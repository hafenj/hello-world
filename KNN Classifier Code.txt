#Import scikit-learn dataset library   
from sklearn import datasets      
from sklearn.model_selection import train_test_split  
from sklearn import metrics   
from sklearn.neighbors import KNeighborsClassifier 
from matplotlib import pyplot as plt 
    
#Load dataset   
cancer = datasets.load_breast_cancer()    
    
# Split dataset into training set and test set   
X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3, random_state=2) # 70% training and 30% test   
  
elbow_test = [] 
for i in range(1,30): 
    #Create a kNN Classifier   
    kNN = KNeighborsClassifier(n_neighbors= i) 
    
    #Train the model using the training sets   
    kNN = kNN.fit(X_train, y_train) 
    
    #Predict the response for test dataset   
    y_pred = kNN.predict(X_test) 
     
    elbow_test.append(1-metrics.accuracy_score(y_test, y_pred)) 
     
# Generating an elbow plot. The optimal k-values are between 18-24 
plt.plot(elbow_test) 
  
kNNF = KNeighborsClassifier(n_neighbors= 18) 
kNNF = kNN.fit(X_train, y_train) 
y_pred_Final = kNNF.predict(X_test) 
  
# Model Accuracy: how often is the classifier correct?   
print("Accuracy:",metrics.accuracy_score(y_test, y_pred_Final))   
    
# Model Precision: what percentage of positive tuples are labeled as such?   
print("Precision:",metrics.precision_score(y_test, y_pred_Final))   
   
# Model Recall: what percentage of positive tuples are labelled as such?   
print("Recall:",metrics.recall_score(y_test, y_pred_Final)) 